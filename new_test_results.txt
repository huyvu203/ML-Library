============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-7.4.4, pluggy-1.6.0 -- /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/bin/python
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: /home/huy/projects/Production-Ready-ML-Library
configfile: pyproject.toml
testpaths: tests
plugins: hypothesis-6.135.14, cov-3.0.0
collecting ... collected 148 items

tests/integration/test_pipeline.py::test_regression_pipeline PASSED      [  0%]
tests/integration/test_pipeline.py::test_classification_pipeline PASSED  [  1%]
tests/integration/test_pipeline.py::test_advanced_regression_pipeline[model0] PASSED [  2%]
tests/integration/test_pipeline.py::test_advanced_regression_pipeline[model1] PASSED [  2%]
tests/integration/test_pipeline.py::test_advanced_classification_pipeline[model0] PASSED [  3%]
tests/integration/test_pipeline.py::test_advanced_classification_pipeline[model1] PASSED [  4%]
tests/unit/test_base_model.py::TestBaseModel::test_initialization PASSED [  4%]
tests/unit/test_base_model.py::TestBaseModel::test_check_is_fitted PASSED [  5%]
tests/unit/test_base_model.py::TestBaseModel::test_fit PASSED            [  6%]
tests/unit/test_base_model.py::TestBaseModel::test_predict PASSED        [  6%]
tests/unit/test_base_model.py::TestBaseModel::test_save_and_load PASSED  [  7%]
tests/unit/test_base_model.py::TestBaseModel::test_save_unfitted_model PASSED [  8%]
tests/unit/test_base_model.py::TestBaseModel::test_load_nonexistent_file PASSED [  8%]
tests/unit/test_base_model.py::TestBaseModel::test_load_wrong_class SKIPPED [  9%]
tests/unit/test_base_model.py::TestBaseModel::test_get_params PASSED     [ 10%]
tests/unit/test_config.py::test_load_yaml PASSED                         [ 10%]
tests/unit/test_config.py::test_load_json PASSED                         [ 11%]
tests/unit/test_config.py::test_load_method PASSED                       [ 12%]
tests/unit/test_config.py::test_load_nonexistent_file PASSED             [ 12%]
tests/unit/test_config.py::test_load_unsupported_extension PASSED        [ 13%]
tests/unit/test_config.py::test_load_invalid_yaml PASSED                 [ 14%]
tests/unit/test_config.py::test_load_invalid_json PASSED                 [ 14%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_yaml FAILED [ 15%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_json FAILED [ 16%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_yaml_with_path_object FAILED [ 16%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_nonexistent_yaml_file PASSED [ 17%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_invalid_yaml_file PASSED [ 18%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_nonexistent_json_file PASSED [ 18%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_invalid_json_file PASSED [ 19%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_yaml FAILED [ 20%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_yml FAILED [ 20%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_json FAILED [ 21%]
tests/unit/test_config_loader.py::TestConfigLoader::test_load_unsupported_extension PASSED [ 22%]
tests/unit/test_knn_models.py::TestKNNModels::test_knn_regressor_init PASSED [ 22%]
tests/unit/test_knn_models.py::TestKNNModels::test_knn_classifier_init PASSED [ 23%]
tests/unit/test_knn_models.py::test_knn_regressor_get_params[3-uniform-auto] PASSED [ 24%]
tests/unit/test_knn_models.py::test_knn_regressor_get_params[5-distance-ball_tree] PASSED [ 25%]
tests/unit/test_knn_models.py::test_knn_regressor_get_params[10-uniform-kd_tree] PASSED [ 25%]
tests/unit/test_knn_models.py::test_knn_classifier_get_params[3-uniform-auto] PASSED [ 26%]
tests/unit/test_knn_models.py::test_knn_classifier_get_params[5-distance-ball_tree] PASSED [ 27%]
tests/unit/test_knn_models.py::test_knn_classifier_get_params[10-uniform-kd_tree] PASSED [ 27%]
tests/unit/test_knn_models.py::test_knn_regressor_fit_predict PASSED     [ 28%]
tests/unit/test_knn_models.py::test_knn_classifier_fit_predict PASSED    [ 29%]
tests/unit/test_knn_models.py::test_knn_regressor_not_fitted_error PASSED [ 29%]
tests/unit/test_knn_models.py::test_knn_classifier_not_fitted_error PASSED [ 30%]
tests/unit/test_knn_models.py::test_validate_data[KNNRegressor-kwargs0] PASSED [ 31%]
tests/unit/test_knn_models.py::test_validate_data[KNNRegressor-kwargs1] PASSED [ 31%]
tests/unit/test_knn_models.py::test_validate_data[KNNClassifier-kwargs2] PASSED [ 32%]
tests/unit/test_knn_models.py::test_validate_data[KNNClassifier-kwargs3] PASSED [ 33%]
tests/unit/test_metrics.py::TestBaseMetrics::test_base_metrics_evaluate_not_implemented PASSED [ 33%]
tests/unit/test_metrics.py::TestRegressionMetrics::test_initialization PASSED [ 34%]
tests/unit/test_metrics.py::TestRegressionMetrics::test_evaluate PASSED  [ 35%]
tests/unit/test_metrics.py::TestRegressionMetrics::test_evaluate_with_lists PASSED [ 35%]
tests/unit/test_metrics.py::TestRegressionMetrics::test_evaluate_perfect_prediction PASSED [ 36%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_initialization_default PASSED [ 37%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_initialization_custom_average PASSED [ 37%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_evaluate_binary PASSED [ 38%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_evaluate_with_probabilities_binary PASSED [ 39%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_evaluate_multiclass PASSED [ 39%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_evaluate_with_probabilities_multiclass PASSED [ 40%]
tests/unit/test_metrics.py::TestClassificationMetrics::test_evaluate_with_invalid_probabilities PASSED [ 41%]
tests/unit/test_models.py::test_linear_regression_initialization PASSED  [ 41%]
tests/unit/test_models.py::test_linear_regression_fit_predict PASSED     [ 42%]
tests/unit/test_models.py::test_linear_regression_score PASSED           [ 43%]
tests/unit/test_models.py::test_linear_regression_not_fitted_error PASSED [ 43%]
tests/unit/test_models.py::test_linear_regression_get_params PASSED      [ 44%]
tests/unit/test_models.py::test_logistic_regression_initialization PASSED [ 45%]
tests/unit/test_models.py::test_logistic_regression_fit_predict PASSED   [ 45%]
tests/unit/test_models.py::test_logistic_regression_predict_proba PASSED [ 46%]
tests/unit/test_models.py::test_logistic_regression_score PASSED         [ 47%]
tests/unit/test_models.py::test_logistic_regression_not_fitted_error PASSED [ 47%]
tests/unit/test_models.py::test_logistic_regression_get_params PASSED    [ 48%]
tests/unit/test_predictor.py::TestPredictor::test_initialization PASSED  [ 49%]
tests/unit/test_predictor.py::TestPredictor::test_initialization_with_unfitted_model PASSED [ 50%]
tests/unit/test_predictor.py::TestPredictor::test_initialization_with_missing_check_method PASSED [ 50%]
tests/unit/test_predictor.py::TestPredictor::test_predict PASSED         [ 51%]
tests/unit/test_predictor.py::TestPredictor::test_predict_with_probabilities PASSED [ 52%]
tests/unit/test_predictor.py::TestPredictor::test_predict_with_probabilities_handling_attribute_error PASSED [ 52%]
tests/unit/test_predictor.py::TestPredictor::test_predict_with_probabilities_handling_not_implemented_error PASSED [ 53%]
tests/unit/test_predictor.py::TestPredictor::test_predict_batch PASSED   [ 54%]
tests/unit/test_predictor.py::TestPredictor::test_predict_batch_with_probabilities PASSED [ 54%]
tests/unit/test_predictor.py::TestPredictor::test_save_and_load_predictions SKIPPED [ 55%]
tests/unit/test_predictor.py::TestPredictor::test_save_predictions_with_probabilities SKIPPED [ 56%]
tests/unit/test_predictor.py::TestPredictor::test_load_predictions_nonexistent_file PASSED [ 56%]
tests/unit/test_predictor_complete.py::TestPredictor::test_initialization PASSED [ 57%]
tests/unit/test_predictor_complete.py::TestPredictor::test_initialization_with_unfitted_model PASSED [ 58%]
tests/unit/test_predictor_complete.py::TestPredictor::test_initialization_with_missing_check_method PASSED [ 58%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict PASSED [ 59%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities FAILED [ 60%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities_handling_attribute_error FAILED [ 60%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities_handling_not_implemented_error FAILED [ 61%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict_batch PASSED [ 62%]
tests/unit/test_predictor_complete.py::TestPredictor::test_predict_batch_with_probabilities FAILED [ 62%]
tests/unit/test_predictor_complete.py::TestPredictor::test_save_and_load_predictions FAILED [ 63%]
tests/unit/test_predictor_complete.py::TestPredictor::test_save_predictions_with_probabilities FAILED [ 64%]
tests/unit/test_predictor_complete.py::TestPredictor::test_load_predictions_nonexistent_file PASSED [ 64%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_initialization PASSED [ 65%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_fit PASSED    [ 66%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_transform FAILED [ 66%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_fit_transform FAILED [ 67%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_inverse_transform FAILED [ 68%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_with_mean_false FAILED [ 68%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_with_std_false FAILED [ 69%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_1d_array FAILED [ 70%]
tests/unit/test_preprocessing.py::TestStandardScaler::test_not_fitted_error PASSED [ 70%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_initialization PASSED [ 71%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_fit FAILED      [ 72%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_transform PASSED [ 72%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_fit_transform PASSED [ 73%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_inverse_transform PASSED [ 74%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_custom_feature_range PASSED [ 75%]
tests/unit/test_preprocessing.py::TestMinMaxScaler::test_not_fitted_error PASSED [ 75%]
tests/unit/test_svm_imports.py::test_svm_imports PASSED                  [ 76%]
tests/unit/test_svm_models.py::TestSVMModels::test_svm_regressor_init PASSED [ 77%]
tests/unit/test_svm_models.py::TestSVMModels::test_svm_classifier_init PASSED [ 77%]
tests/unit/test_svm_models.py::test_svm_regressor_get_params[linear-1.0-scale] PASSED [ 78%]
tests/unit/test_svm_models.py::test_svm_regressor_get_params[rbf-0.5-auto] PASSED [ 79%]
tests/unit/test_svm_models.py::test_svm_regressor_get_params[poly-2.0-0.1] PASSED [ 79%]
tests/unit/test_svm_models.py::test_svm_classifier_get_params[linear-1.0-scale] PASSED [ 80%]
tests/unit/test_svm_models.py::test_svm_classifier_get_params[rbf-0.5-auto] PASSED [ 81%]
tests/unit/test_svm_models.py::test_svm_classifier_get_params[poly-2.0-0.1] PASSED [ 81%]
tests/unit/test_svm_models.py::test_svm_regressor_fit_predict PASSED     [ 82%]
tests/unit/test_svm_models.py::test_svm_classifier_fit_predict PASSED    [ 83%]
tests/unit/test_svm_models.py::test_svm_regressor_not_fitted_error PASSED [ 83%]
tests/unit/test_svm_models.py::test_svm_classifier_not_fitted_error PASSED [ 84%]
tests/unit/test_svm_models.py::test_svm_classifier_probability_error PASSED [ 85%]
tests/unit/test_tree_models.py::TestTreeModels::test_decision_tree_regressor_init PASSED [ 85%]
tests/unit/test_tree_models.py::TestTreeModels::test_decision_tree_classifier_init PASSED [ 86%]
tests/unit/test_tree_models.py::TestTreeModels::test_random_forest_regressor_init PASSED [ 87%]
tests/unit/test_tree_models.py::TestTreeModels::test_random_forest_classifier_init PASSED [ 87%]
tests/unit/test_tree_models.py::TestTreeModels::test_xgboost_regressor_init PASSED [ 88%]
tests/unit/test_tree_models.py::TestTreeModels::test_xgboost_classifier_init PASSED [ 89%]
tests/unit/test_tree_models.py::test_regressor_fit_predict[DecisionTreeRegressor-model_params0] PASSED [ 89%]
tests/unit/test_tree_models.py::test_regressor_fit_predict[RandomForestRegressor-model_params1] PASSED [ 90%]
tests/unit/test_tree_models.py::test_regressor_fit_predict[XGBoostRegressor-model_params2] PASSED [ 91%]
tests/unit/test_tree_models.py::test_classifier_fit_predict[DecisionTreeClassifier-model_params0] PASSED [ 91%]
tests/unit/test_tree_models.py::test_classifier_fit_predict[RandomForestClassifier-model_params1] PASSED [ 92%]
tests/unit/test_tree_models.py::test_classifier_fit_predict[XGBoostClassifier-model_params2] PASSED [ 93%]
tests/unit/temp/test_imports.py::test_base_imports PASSED                [ 93%]
tests/unit/temp/test_imports.py::test_linear_models PASSED               [ 94%]
tests/unit/temp/test_imports.py::test_tree_models PASSED                 [ 95%]
tests/unit/temp/test_imports.py::test_boosting_models PASSED             [ 95%]
tests/unit/temp/test_imports.py::test_svm_models PASSED                  [ 96%]
tests/unit/temp/test_imports.py::test_knn_models PASSED                  [ 97%]
tests/unit/temp/test_svm.py::test_svm_regressor_init PASSED              [ 97%]
tests/unit/temp/test_svm.py::test_svm_classifier_init PASSED             [ 98%]
tests/unit/temp/test_svm.py::test_svm_regressor_fit_predict PASSED       [ 99%]
tests/unit/temp/test_svm.py::test_svm_classifier_fit_predict PASSED      [100%]

=================================== FAILURES ===================================
_______________________ TestConfigLoader.test_load_yaml ________________________

self = <test_config_loader.TestConfigLoader object at 0x75be146360c0>

    def test_load_yaml(self):
        """Test loading a YAML configuration file."""
        # Create a temporary YAML config file
        config = {"model": {"name": "test", "params": {"alpha": 0.1}}}
    
        with tempfile.NamedTemporaryFile(suffix=".yaml", delete=False) as tmp:
>           yaml.dump(config, tmp)

tests/unit/test_config_loader.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:253: in dump
    return dump_all([data], stream, Dumper=Dumper, **kwds)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:241: in dump_all
    dumper.represent(data)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/representer.py:28: in represent
    self.serialize(node)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:54: in serialize
    self.serialize_node(node, None, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:108: in serialize_node
    self.serialize_node(value, node, key)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:107: in serialize_node
    self.serialize_node(key, node, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:89: in serialize_node
    self.emit(ScalarEvent(alias, node.tag, implicit, node.value,
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:115: in emit
    self.state()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:393: in expect_first_block_mapping_key
    return self.expect_block_mapping_key(first=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:403: in expect_block_mapping_key
    self.expect_node(mapping=True, simple_key=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:244: in expect_node
    self.expect_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:268: in expect_scalar
    self.process_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:533: in process_scalar
    self.write_plain(self.analysis.scalar, split)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:1132: in write_plain
    self.stream.write(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('model',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
_______________________ TestConfigLoader.test_load_json ________________________

self = <test_config_loader.TestConfigLoader object at 0x75be14636750>

    def test_load_json(self):
        """Test loading a JSON configuration file."""
        # Create a temporary JSON config file
        config = {"model": {"name": "test", "params": {"alpha": 0.1}}}
    
        with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as tmp:
>           json.dump(config, tmp)

tests/unit/test_config_loader.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/json/__init__.py:180: in dump
    fp.write(chunk)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('{',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
_______________ TestConfigLoader.test_load_yaml_with_path_object _______________

self = <test_config_loader.TestConfigLoader object at 0x75be14636090>

    def test_load_yaml_with_path_object(self):
        """Test loading a YAML configuration file using a Path object."""
        # Create a temporary YAML config file
        config = {"model": {"name": "test", "params": {"alpha": 0.1}}}
    
        with tempfile.NamedTemporaryFile(suffix=".yaml", delete=False) as tmp:
>           yaml.dump(config, tmp)

tests/unit/test_config_loader.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:253: in dump
    return dump_all([data], stream, Dumper=Dumper, **kwds)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:241: in dump_all
    dumper.represent(data)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/representer.py:28: in represent
    self.serialize(node)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:54: in serialize
    self.serialize_node(node, None, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:108: in serialize_node
    self.serialize_node(value, node, key)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:107: in serialize_node
    self.serialize_node(key, node, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:89: in serialize_node
    self.emit(ScalarEvent(alias, node.tag, implicit, node.value,
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:115: in emit
    self.state()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:393: in expect_first_block_mapping_key
    return self.expect_block_mapping_key(first=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:403: in expect_block_mapping_key
    self.expect_node(mapping=True, simple_key=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:244: in expect_node
    self.expect_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:268: in expect_scalar
    self.process_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:533: in process_scalar
    self.write_plain(self.analysis.scalar, split)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:1132: in write_plain
    self.stream.write(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('model',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
_____________________ TestConfigLoader.test_load_auto_yaml _____________________

self = <test_config_loader.TestConfigLoader object at 0x75be14635cd0>

    def test_load_auto_yaml(self):
        """Test auto-detection of YAML files."""
        config = {"model": {"name": "test"}}
    
        with tempfile.NamedTemporaryFile(suffix=".yaml", delete=False) as tmp:
>           yaml.dump(config, tmp)

tests/unit/test_config_loader.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:253: in dump
    return dump_all([data], stream, Dumper=Dumper, **kwds)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:241: in dump_all
    dumper.represent(data)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/representer.py:28: in represent
    self.serialize(node)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:54: in serialize
    self.serialize_node(node, None, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:108: in serialize_node
    self.serialize_node(value, node, key)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:107: in serialize_node
    self.serialize_node(key, node, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:89: in serialize_node
    self.emit(ScalarEvent(alias, node.tag, implicit, node.value,
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:115: in emit
    self.state()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:393: in expect_first_block_mapping_key
    return self.expect_block_mapping_key(first=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:403: in expect_block_mapping_key
    self.expect_node(mapping=True, simple_key=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:244: in expect_node
    self.expect_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:268: in expect_scalar
    self.process_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:533: in process_scalar
    self.write_plain(self.analysis.scalar, split)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:1132: in write_plain
    self.stream.write(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('model',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
_____________________ TestConfigLoader.test_load_auto_yml ______________________

self = <test_config_loader.TestConfigLoader object at 0x75be14635c10>

    def test_load_auto_yml(self):
        """Test auto-detection of YML files."""
        config = {"model": {"name": "test"}}
    
        with tempfile.NamedTemporaryFile(suffix=".yml", delete=False) as tmp:
>           yaml.dump(config, tmp)

tests/unit/test_config_loader.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:253: in dump
    return dump_all([data], stream, Dumper=Dumper, **kwds)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/__init__.py:241: in dump_all
    dumper.represent(data)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/representer.py:28: in represent
    self.serialize(node)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:54: in serialize
    self.serialize_node(node, None, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:108: in serialize_node
    self.serialize_node(value, node, key)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:107: in serialize_node
    self.serialize_node(key, node, None)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/serializer.py:89: in serialize_node
    self.emit(ScalarEvent(alias, node.tag, implicit, node.value,
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:115: in emit
    self.state()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:393: in expect_first_block_mapping_key
    return self.expect_block_mapping_key(first=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:403: in expect_block_mapping_key
    self.expect_node(mapping=True, simple_key=True)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:244: in expect_node
    self.expect_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:268: in expect_scalar
    self.process_scalar()
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:533: in process_scalar
    self.write_plain(self.analysis.scalar, split)
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/yaml/emitter.py:1132: in write_plain
    self.stream.write(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('model',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
_____________________ TestConfigLoader.test_load_auto_json _____________________

self = <test_config_loader.TestConfigLoader object at 0x75be14636ba0>

    def test_load_auto_json(self):
        """Test auto-detection of JSON files."""
        config = {"model": {"name": "test"}}
    
        with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as tmp:
>           json.dump(config, tmp)

tests/unit/test_config_loader.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/json/__init__.py:180: in dump
    fp.write(chunk)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ('{',), kwargs = {}

    @_functools.wraps(func)
    def func_wrapper(*args, **kwargs):
>       return func(*args, **kwargs)
E       TypeError: a bytes-like object is required, not 'str'

/usr/lib/python3.12/tempfile.py:638: TypeError
________________ TestPredictor.test_predict_with_probabilities _________________

self = <test_predictor_complete.TestPredictor object at 0x75be1463b050>

    def test_predict_with_probabilities(self):
        """Test the predict method with probabilities."""
        # Create a mock model for testing
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.return_value = np.array([1, 0, 1])
>       model.predict_proba.return_value = np.array([
            [0.2, 0.8],
            [0.7, 0.3],
            [0.1, 0.9]
        ])

tests/unit/test_predictor_complete.py:73: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock spec='MockModel' id='129459268499840'>, name = 'predict_proba'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
>               raise AttributeError("Mock object has no attribute %r" % name)
E               AttributeError: Mock object has no attribute 'predict_proba'

/usr/lib/python3.12/unittest/mock.py:658: AttributeError
____ TestPredictor.test_predict_with_probabilities_handling_attribute_error ____

self = <test_predictor_complete.TestPredictor object at 0x75be1463b7d0>

    def test_predict_with_probabilities_handling_attribute_error(self):
        """Test handling of AttributeError when requesting probabilities."""
        # Create a mock model that raises AttributeError
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.return_value = np.array([1, 0, 1])
    
        # Make predict_proba raise AttributeError
>       model.predict_proba.side_effect = AttributeError("'MockModel' has no attribute 'predict_proba'")

tests/unit/test_predictor_complete.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock spec='MockModel' id='129459244311008'>, name = 'predict_proba'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
>               raise AttributeError("Mock object has no attribute %r" % name)
E               AttributeError: Mock object has no attribute 'predict_proba'

/usr/lib/python3.12/unittest/mock.py:658: AttributeError
_ TestPredictor.test_predict_with_probabilities_handling_not_implemented_error _

self = <test_predictor_complete.TestPredictor object at 0x75be1463a1b0>

    def test_predict_with_probabilities_handling_not_implemented_error(self):
        """Test handling of NotImplementedError when requesting probabilities."""
        # Create a mock model that raises NotImplementedError
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.return_value = np.array([1, 0, 1])
    
        # Make predict_proba raise NotImplementedError
>       model.predict_proba.side_effect = NotImplementedError("Probabilities not implemented")

tests/unit/test_predictor_complete.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock spec='MockModel' id='129459243997456'>, name = 'predict_proba'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
>               raise AttributeError("Mock object has no attribute %r" % name)
E               AttributeError: Mock object has no attribute 'predict_proba'

/usr/lib/python3.12/unittest/mock.py:658: AttributeError
_____________ TestPredictor.test_predict_batch_with_probabilities ______________

self = <test_predictor_complete.TestPredictor object at 0x75be14638260>

    def test_predict_batch_with_probabilities(self):
        """Test the predict_batch method with probabilities."""
        # Create a mock model for testing
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.side_effect = [
            np.array([1, 0]),
            np.array([1, 1])
        ]
>       model.predict_proba.side_effect = [
            np.array([[0.2, 0.8], [0.7, 0.3]]),
            np.array([[0.1, 0.9], [0.3, 0.7]])
        ]

tests/unit/test_predictor_complete.py:181: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock spec='MockModel' id='129459244122960'>, name = 'predict_proba'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
>               raise AttributeError("Mock object has no attribute %r" % name)
E               AttributeError: Mock object has no attribute 'predict_proba'

/usr/lib/python3.12/unittest/mock.py:658: AttributeError
_________________ TestPredictor.test_save_and_load_predictions _________________

self = <test_predictor_complete.TestPredictor object at 0x75be1463b680>

    def test_save_and_load_predictions(self):
        """Test saving and loading predictions."""
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.return_value = np.array([1, 2, 3])
    
        predictor = Predictor(model)
        X = [[1, 2], [3, 4], [5, 6]]
    
        # Get predictions
        predictions = predictor.predict(X)
    
        # Create temporary file
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            temp_path = tmp.name
    
        try:
            # Save predictions
            predictor.save_predictions(predictions, temp_path)
            assert os.path.exists(temp_path)
    
            # Load predictions
>           loaded_predictions = predictor.load_predictions(temp_path)

tests/unit/test_predictor_complete.py:227: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
inference/predictor.py:169: in load_predictions
    return np.load(file_path, allow_pickle=True)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

file = PosixPath('/tmp/tmpddwb0757'), mmap_mode = None, allow_pickle = True
fix_imports = True, encoding = 'ASCII'

    @set_module('numpy')
    def load(file, mmap_mode=None, allow_pickle=False, fix_imports=True,
             encoding='ASCII', *, max_header_size=format._MAX_HEADER_SIZE):
        """
        Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.
    
        .. warning:: Loading files that contain object arrays uses the ``pickle``
                     module, which is not secure against erroneous or maliciously
                     constructed data. Consider passing ``allow_pickle=False`` to
                     load data that is known not to contain object arrays for the
                     safer handling of untrusted sources.
    
        Parameters
        ----------
        file : file-like object, string, or pathlib.Path
            The file to read. File-like objects must support the
            ``seek()`` and ``read()`` methods and must always
            be opened in binary mode.  Pickled files require that the
            file-like object support the ``readline()`` method as well.
        mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional
            If not None, then memory-map the file, using the given mode (see
            `numpy.memmap` for a detailed description of the modes).  A
            memory-mapped array is kept on disk. However, it can be accessed
            and sliced like any ndarray.  Memory mapping is especially useful
            for accessing small fragments of large files without reading the
            entire file into memory.
        allow_pickle : bool, optional
            Allow loading pickled object arrays stored in npy files. Reasons for
            disallowing pickles include security, as loading pickled data can
            execute arbitrary code. If pickles are disallowed, loading object
            arrays will fail. Default: False
    
            .. versionchanged:: 1.16.3
                Made default False in response to CVE-2019-6446.
    
        fix_imports : bool, optional
            Only useful when loading Python 2 generated pickled files on Python 3,
            which includes npy/npz files containing object arrays. If `fix_imports`
            is True, pickle will try to map the old Python 2 names to the new names
            used in Python 3.
        encoding : str, optional
            What encoding to use when reading Python 2 strings. Only useful when
            loading Python 2 generated pickled files in Python 3, which includes
            npy/npz files containing object arrays. Values other than 'latin1',
            'ASCII', and 'bytes' are not allowed, as they can corrupt numerical
            data. Default: 'ASCII'
        max_header_size : int, optional
            Maximum allowed size of the header.  Large headers may not be safe
            to load securely and thus require explicitly passing a larger value.
            See :py:func:`ast.literal_eval()` for details.
            This option is ignored when `allow_pickle` is passed.  In that case
            the file is by definition trusted and the limit is unnecessary.
    
        Returns
        -------
        result : array, tuple, dict, etc.
            Data stored in the file. For ``.npz`` files, the returned instance
            of NpzFile class must be closed to avoid leaking file descriptors.
    
        Raises
        ------
        OSError
            If the input file does not exist or cannot be read.
        UnpicklingError
            If ``allow_pickle=True``, but the file cannot be loaded as a pickle.
        ValueError
            The file contains an object array, but ``allow_pickle=False`` given.
        EOFError
            When calling ``np.load`` multiple times on the same file handle,
            if all data has already been read
    
        See Also
        --------
        save, savez, savez_compressed, loadtxt
        memmap : Create a memory-map to an array stored in a file on disk.
        lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.
    
        Notes
        -----
        - If the file contains pickle data, then whatever object is stored
          in the pickle is returned.
        - If the file is a ``.npy`` file, then a single array is returned.
        - If the file is a ``.npz`` file, then a dictionary-like object is
          returned, containing ``{filename: array}`` key-value pairs, one for
          each file in the archive.
        - If the file is a ``.npz`` file, the returned value supports the
          context manager protocol in a similar fashion to the open function::
    
            with load('foo.npz') as data:
                a = data['a']
    
          The underlying file descriptor is closed when exiting the 'with'
          block.
    
        Examples
        --------
        Store data to disk, and load it again:
    
        >>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))
        >>> np.load('/tmp/123.npy')
        array([[1, 2, 3],
               [4, 5, 6]])
    
        Store compressed data to disk, and load it again:
    
        >>> a=np.array([[1, 2, 3], [4, 5, 6]])
        >>> b=np.array([1, 2])
        >>> np.savez('/tmp/123.npz', a=a, b=b)
        >>> data = np.load('/tmp/123.npz')
        >>> data['a']
        array([[1, 2, 3],
               [4, 5, 6]])
        >>> data['b']
        array([1, 2])
        >>> data.close()
    
        Mem-map the stored array, and then access the second row
        directly from disk:
    
        >>> X = np.load('/tmp/123.npy', mmap_mode='r')
        >>> X[1, :]
        memmap([4, 5, 6])
    
        """
        if encoding not in ('ASCII', 'latin1', 'bytes'):
            # The 'encoding' value for pickle also affects what encoding
            # the serialized binary data of NumPy arrays is loaded
            # in. Pickle does not pass on the encoding information to
            # NumPy. The unpickling code in numpy.core.multiarray is
            # written to assume that unicode data appearing where binary
            # should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.
            #
            # Other encoding values can corrupt binary data, and we
            # purposefully disallow them. For the same reason, the errors=
            # argument is not exposed, as values other than 'strict'
            # result can similarly silently corrupt numerical data.
            raise ValueError("encoding must be 'ASCII', 'latin1', or 'bytes'")
    
        pickle_kwargs = dict(encoding=encoding, fix_imports=fix_imports)
    
        with contextlib.ExitStack() as stack:
            if hasattr(file, 'read'):
                fid = file
                own_fid = False
            else:
                fid = stack.enter_context(open(os_fspath(file), "rb"))
                own_fid = True
    
            # Code to distinguish from NumPy binary files and pickles.
            _ZIP_PREFIX = b'PK\x03\x04'
            _ZIP_SUFFIX = b'PK\x05\x06' # empty zip files start with this
            N = len(format.MAGIC_PREFIX)
            magic = fid.read(N)
            if not magic:
>               raise EOFError("No data left in file")
E               EOFError: No data left in file

../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/numpy/lib/npyio.py:436: EOFError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | inference.predictor:__init__:40 | Initialized predictor with model MockModel
2025-06-23 09:46:32 | DEBUG    | inference.predictor:predict:61 | Making predictions on 3 samples
2025-06-23 09:46:32 | INFO     | inference.predictor:save_predictions:145 | Saving predictions to /tmp/tmpddwb0757
2025-06-23 09:46:32 | INFO     | inference.predictor:load_predictions:166 | Loading predictions from /tmp/tmpddwb0757
____________ TestPredictor.test_save_predictions_with_probabilities ____________

self = <test_predictor_complete.TestPredictor object at 0x75be1463b980>

    def test_save_predictions_with_probabilities(self):
        """Test saving predictions with probabilities."""
        model = Mock(spec=BaseModel)
        model.check_is_fitted.return_value = None
        model.predict.return_value = np.array([1, 0, 1])
>       model.predict_proba.return_value = np.array([
            [0.2, 0.8],
            [0.7, 0.3],
            [0.1, 0.9]
        ])

tests/unit/test_predictor_complete.py:241: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <Mock spec='MockModel' id='129459244317968'>, name = 'predict_proba'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
>               raise AttributeError("Mock object has no attribute %r" % name)
E               AttributeError: Mock object has no attribute 'predict_proba'

/usr/lib/python3.12/unittest/mock.py:658: AttributeError
______________________ TestStandardScaler.test_transform _______________________

self = <test_preprocessing.TestStandardScaler object at 0x75be146393a0>

    def test_transform(self):
        """Test transform method of StandardScaler."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = StandardScaler()
        scaler.fit(X)
    
>       X_scaled = scaler.transform(X)

tests/unit/test_preprocessing.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be14452780>
X = array([[1, 2],
       [3, 4],
       [5, 6]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
>           X_scaled -= self.mean_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:80: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
____________________ TestStandardScaler.test_fit_transform _____________________

self = <test_preprocessing.TestStandardScaler object at 0x75be1463bb90>

    def test_fit_transform(self):
        """Test fit_transform method of StandardScaler."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = StandardScaler()
    
>       X_scaled = scaler.fit_transform(X)

tests/unit/test_preprocessing.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
preprocessing/transformers.py:95: in fit_transform
    return self.fit(X).transform(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be14425a60>
X = array([[1, 2],
       [3, 4],
       [5, 6]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
>           X_scaled -= self.mean_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:80: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
__________________ TestStandardScaler.test_inverse_transform ___________________

self = <test_preprocessing.TestStandardScaler object at 0x75be14638530>

    def test_inverse_transform(self):
        """Test inverse_transform method of StandardScaler."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = StandardScaler()
        scaler.fit(X)
    
>       X_scaled = scaler.transform(X)

tests/unit/test_preprocessing.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be14424e60>
X = array([[1, 2],
       [3, 4],
       [5, 6]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
>           X_scaled -= self.mean_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:80: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
___________________ TestStandardScaler.test_with_mean_false ____________________

self = <test_preprocessing.TestStandardScaler object at 0x75be146a0080>

    def test_with_mean_false(self):
        """Test StandardScaler with with_mean=False."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = StandardScaler(with_mean=False)
>       X_scaled = scaler.fit_transform(X)

tests/unit/test_preprocessing.py:72: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
preprocessing/transformers.py:95: in fit_transform
    return self.fit(X).transform(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be144267e0>
X = array([[1, 2],
       [3, 4],
       [5, 6]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
            X_scaled -= self.mean_
        if self.with_std:
>           X_scaled /= self.scale_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:82: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
____________________ TestStandardScaler.test_with_std_false ____________________

self = <test_preprocessing.TestStandardScaler object at 0x75be146a0230>

    def test_with_std_false(self):
        """Test StandardScaler with with_std=False."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = StandardScaler(with_std=False)
>       X_scaled = scaler.fit_transform(X)

tests/unit/test_preprocessing.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
preprocessing/transformers.py:95: in fit_transform
    return self.fit(X).transform(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be144531d0>
X = array([[1, 2],
       [3, 4],
       [5, 6]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
>           X_scaled -= self.mean_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:80: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
_______________________ TestStandardScaler.test_1d_array _______________________

self = <test_preprocessing.TestStandardScaler object at 0x75be146a0320>

    def test_1d_array(self):
        """Test that 1D arrays are handled correctly."""
        X = np.array([1, 3, 5])
        scaler = StandardScaler()
>       X_scaled = scaler.fit_transform(X)

tests/unit/test_preprocessing.py:92: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
preprocessing/transformers.py:95: in fit_transform
    return self.fit(X).transform(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <preprocessing.transformers.StandardScaler object at 0x75be14427530>
X = array([[1],
       [3],
       [5]])

    def transform(self, X: np.ndarray) -> np.ndarray:
        """Scale features of X according to feature-wise statistics.
    
        Args:
            X: The data to scale
    
        Returns:
            Scaled data
        """
        if not self._fitted:
            raise ValueError("StandardScaler is not fitted yet. Call 'fit' first.")
    
        X = self._validate_data(X)
    
        if self.mean_ is None or self.scale_ is None:
            raise ValueError("StandardScaler is not fitted correctly.")
    
        X_scaled = X.copy()
        if self.with_mean:
>           X_scaled -= self.mean_
E           numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'

preprocessing/transformers.py:80: UFuncTypeError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:58 | StandardScaler fitted
__________________________ TestMinMaxScaler.test_fit ___________________________

self = <test_preprocessing.TestMinMaxScaler object at 0x75be146a0860>

    def test_fit(self):
        """Test fitting of MinMaxScaler."""
        X = np.array([[1, 2], [3, 4], [5, 6]])
        scaler = MinMaxScaler()
        fitted_scaler = scaler.fit(X)
    
        assert fitted_scaler is scaler  # Check if it returns self
        assert scaler._fitted is True
    
        # Check computed statistics
>       np.testing.assert_almost_equal(scaler.min_, np.array([1, 2]))

tests/unit/test_preprocessing.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/contextlib.py:81: in inner
    return func(*args, **kwds)
/usr/lib/python3.12/contextlib.py:81: in inner
    return func(*args, **kwds)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_array_almost_equal.<locals>.compare at 0x75be144bb7e0>, array([-0.25, -0.5 ]), array([1, 2]))
kwds = {'err_msg': '', 'header': 'Arrays are not almost equal to 7 decimals', 'precision': 7, 'verbose': True}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Arrays are not almost equal to 7 decimals
E           
E           Mismatched elements: 2 / 2 (100%)
E           Max absolute difference: 2.5
E           Max relative difference: 1.25
E            x: array([-0.25, -0.5 ])
E            y: array([1, 2])

/usr/lib/python3.12/contextlib.py:81: AssertionError
----------------------------- Captured stderr call -----------------------------
2025-06-23 09:46:32 | DEBUG    | preprocessing.transformers:fit:185 | MinMaxScaler fitted
=============================== warnings summary ===============================
../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/pytest_cov/plugin.py:256
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/pytest_cov/plugin.py:256: PytestDeprecationWarning: The hookimpl CovPlugin.pytest_configure_node uses old-style configuration options (marks or attributes).
  Please use the pytest.hookimpl(optionalhook=True) decorator instead
   to configure the hooks.
   See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
    def pytest_configure_node(self, node):

../../.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/pytest_cov/plugin.py:265
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/pytest_cov/plugin.py:265: PytestDeprecationWarning: The hookimpl CovPlugin.pytest_testnodedown uses old-style configuration options (marks or attributes).
  Please use the pytest.hookimpl(optionalhook=True) decorator instead
   to configure the hooks.
   See https://docs.pytest.org/en/latest/deprecations.html#configuring-hook-specs-impls-using-markers
    def pytest_testnodedown(self, node, error):

tests/unit/test_tree_models.py::test_classifier_fit_predict[XGBoostClassifier-model_params2]
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [09:46:33] WARNING: /workspace/src/learner.cc:740: 
  Parameters: { "use_label_encoder" } are not used.
  
    warnings.warn(smsg, UserWarning)

tests/unit/temp/test_imports.py::test_base_imports
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_base_imports returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_imports.py::test_linear_models
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_linear_models returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_imports.py::test_tree_models
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_tree_models returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_imports.py::test_boosting_models
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_boosting_models returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_imports.py::test_svm_models
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_svm_models returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_imports.py::test_knn_models
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_imports.py::test_knn_models returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_svm.py::test_svm_regressor_init
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_svm.py::test_svm_regressor_init returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_svm.py::test_svm_classifier_init
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_svm.py::test_svm_classifier_init returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_svm.py::test_svm_regressor_fit_predict
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_svm.py::test_svm_regressor_fit_predict returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

tests/unit/temp/test_svm.py::test_svm_classifier_fit_predict
  /home/huy/.cache/pypoetry/virtualenvs/ml-library-R55_URkK-py3.12/lib/python3.12/site-packages/_pytest/python.py:198: PytestReturnNotNoneWarning: Expected None, but tests/unit/temp/test_svm.py::test_svm_classifier_fit_predict returned True, which will be an error in a future version of pytest.  Did you mean to use `assert` instead of `return`?
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform linux, python 3.12.3-final-0 -----------
Name                            Stmts   Miss  Cover   Missing
-------------------------------------------------------------
config/__init__.py                  2      0   100%
config/loader.py                   40      0   100%
evaluation/__init__.py              2      0   100%
evaluation/metrics.py              48      0   100%
inference/__init__.py               2      0   100%
inference/predictor.py             72     11    85%   183-204
models/__init__.py                  9      0   100%
models/base.py                     43      3    93%   53, 65, 105
models/classification.py          104     27    74%   75, 94, 112-113, 131-136, 139-144, 158-161, 163-166, 180-181, 197, 200, 237, 267, 270
models/knn_models.py               99      9    91%   65-67, 136, 227-229, 300, 316
models/random_forest.py           112     15    87%   65-67, 128, 144, 157, 177, 235-237, 299, 314, 330, 343, 363
models/regression.py               75     22    71%   72-73, 88-118, 125-126, 145, 162, 193, 196
models/svm_models.py              106     11    90%   69-71, 142, 176, 242-244, 318, 340, 375
models/tree_models.py             110     15    86%   61-63, 122, 138, 151, 170, 224-226, 286, 301, 317, 330, 349
models/xgboost_models.py          114     15    87%   69-71, 133, 149, 162, 183, 245-247, 312, 327, 343, 356, 377
preprocessing/__init__.py           2      0   100%
preprocessing/transformers.py     101     16    84%   76, 84, 109-120, 132, 204, 238, 255, 258
training/__init__.py                2      0   100%
training/trainer.py                45      3    93%   79-80, 130
utils/__init__.py                   2      0   100%
utils/logger.py                    13      1    92%   42
-------------------------------------------------------------
TOTAL                            1103    148    87%
Coverage XML written to file coverage.xml

=========================== short test summary info ============================
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_yaml - T...
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_json - T...
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_yaml_with_path_object
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_yaml
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_yml
FAILED tests/unit/test_config_loader.py::TestConfigLoader::test_load_auto_json
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities_handling_attribute_error
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_predict_with_probabilities_handling_not_implemented_error
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_predict_batch_with_probabilities
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_save_and_load_predictions
FAILED tests/unit/test_predictor_complete.py::TestPredictor::test_save_predictions_with_probabilities
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_transform
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_fit_transform
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_inverse_transform
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_with_mean_false
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_with_std_false
FAILED tests/unit/test_preprocessing.py::TestStandardScaler::test_1d_array - ...
FAILED tests/unit/test_preprocessing.py::TestMinMaxScaler::test_fit - Asserti...
============ 19 failed, 126 passed, 3 skipped, 13 warnings in 3.03s ============
